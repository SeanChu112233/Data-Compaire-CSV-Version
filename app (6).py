import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, ShuffleSplit
from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
import plotly.express as px

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨å‡ºåŠ›-æ¸©åº¦/æ—¶é—´æ¡ä»¶æ•°æ®åˆ†æå·¥å…· for Mabel",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š æ¨å‡ºåŠ›-æ¸©åº¦/æ—¶é—´æ¡ä»¶æ•°æ®åˆ†æå·¥å…· for Mabel")
st.markdown("""
    è¯¥å·¥å…·ç”¨äºåˆ†ææ¸©åº¦(temp)ã€æ—¶é—´(time)ä¸æ¨å‡ºåŠ›(force)ä¹‹é—´çš„å…³ç³»ï¼Œ
    æ”¯æŒå¤šç§å›å½’æ¨¡å‹åˆ†æï¼Œå¹¶æä¾›å¯è§†åŒ–ç»“æœã€‚è¯·ä¸Šä¼ åŒ…å«ç›¸å…³æ•°æ®çš„CSVæ–‡ä»¶ã€‚
""")

# ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œå‚æ•°è®¾ç½®
with st.sidebar:
    st.header("è®¾ç½®")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ•°æ®æ–‡ä»¶", type=["csv"])
    
    # æ¨¡å‹é€‰æ‹©
    model_option = st.selectbox(
        "é€‰æ‹©å›å½’æ¨¡å‹",
        ("éšæœºæ£®æ—", "æ¢¯åº¦æå‡æ ‘", "å¤šé¡¹å¼å›å½’", "çº¿æ€§å›å½’")
    )
    
    # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
    st.subheader("æ•°æ®ä¿¡æ¯")
    data_info = st.empty()

# ä¸»ç¨‹åº
def main():
    # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†æ–‡ä»¶
    if uploaded_file is not None:
        try:
            # è¯»å–CSVæ–‡ä»¶
            data = pd.read_csv(uploaded_file)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['temp', 'time', 'force']
            data.columns = [col.lower() for col in data.columns]  # è½¬æ¢åˆ—åä¸ºå°å†™
            missing = [col for col in required_columns if col not in data.columns]
            
            if missing:
                st.error(f"æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing)}")
                return
            
            # é‡å‘½ååˆ—åï¼Œé¦–å­—æ¯å¤§å†™
            data = data.rename(columns={
                'temp': 'Temp',
                'time': 'Time',
                'force': 'Force'
            })
            
            # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
            with st.sidebar:
                data_info.dataframe(data.describe(), use_container_width=True)
                st.write(f"æ•°æ®é‡: {len(data)} æ¡")
            
            # æ˜¾ç¤ºåŸå§‹æ•°æ®
            with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=False):
                st.dataframe(data, use_container_width=True)
            
            # è®­ç»ƒæ¨¡å‹
            models = train_models(data)
            
            # æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°ç»“æœ
            show_model_evaluation(models, data)
            
            # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
            show_visualizations(models, data, model_option)
            
            # äº¤äº’å¼é¢„æµ‹
            show_prediction_tool(models, data, model_option)
            
        except Exception as e:
            st.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
    else:
        # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
        st.info("è¯·ä¸Šä¼ CSVæ–‡ä»¶å¼€å§‹åˆ†æã€‚ç¤ºä¾‹æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š")
        sample_data = pd.DataFrame({
            'temp': [70, 70, 70, 90, 90],
            'time': [60, 180, 300, 60, 180],
            'force': [3.4, 3.1, 3.3, 3.1, 2.8]
        })
        st.dataframe(sample_data, use_container_width=True)

def train_models(data):
    """è®­ç»ƒæ‰€æœ‰å›å½’æ¨¡å‹"""
    X = data[['Temp', 'Time']]
    y = data['Force']
    
    models = {}
    
    # 1. çº¿æ€§å›å½’
    linear_model = LinearRegression()
    linear_model.fit(X, y)
    models["çº¿æ€§å›å½’"] = {
        "model": linear_model,
        "type": "linear"
    }
    
    # 2. å¤šé¡¹å¼å›å½’ (äºŒæ¬¡é¡¹)
    poly = PolynomialFeatures(degree=2, include_bias=False)
    X_poly = poly.fit_transform(X)
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    models["å¤šé¡¹å¼å›å½’"] = {
        "model": poly_model,
        "type": "polynomial",
        "poly_transform": poly
    }
    
    # 3. éšæœºæ£®æ—å›å½’
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X, y)
    models["éšæœºæ£®æ—"] = {
        "model": rf_model,
        "type": "nonlinear"
    }
    
    # 4. æ¢¯åº¦æå‡æ ‘å›å½’
    gb_model = GradientBoostingRegressor( n_estimators=30,        # å‡å°‘æ ‘çš„æ•°é‡ï¼ˆä»100â†’30ï¼‰
    max_depth=3,            # é™åˆ¶æ ‘æ·±åº¦ï¼ˆé˜²æ­¢è¿‡åº¦åˆ†è£‚ï¼‰
    min_samples_leaf=2,     # å¢åŠ å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
    subsample=0.8,          # ä½¿ç”¨80%çš„æ ·æœ¬è®­ç»ƒæ¯æ£µæ ‘
    random_state=42)
    gb_model.fit(X, y)
    models["æ¢¯åº¦æå‡æ ‘"] = {
        "model": gb_model,
        "type": "nonlinear"
    }
    
    # è¯„ä¼°æ¨¡å‹
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
    for name, model_info in models.items():
        model = model_info["model"]
        
        if model_info["type"] == "polynomial":
            X_processed = model_info["poly_transform"].transform(X)
        else:
            X_processed = X
        
        # è®¡ç®—äº¤å‰éªŒè¯å¾—åˆ†
        cv_scores = cross_val_score(model, X_processed, y, cv=cv, scoring='r2')
        cv_rmse = cross_val_score(model, X_processed, y, cv=cv, scoring='neg_mean_squared_error')
        
        # è®¡ç®—è®­ç»ƒRÂ²å’ŒRMSE
        y_pred = predict_with_model(name, models, X)
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        
        model_info["cv_r2_mean"] = np.mean(cv_scores)
        model_info["cv_r2_std"] = np.std(cv_scores)
        model_info["cv_rmse_mean"] = np.mean(np.sqrt(-cv_rmse))
        model_info["train_r2"] = r2
        model_info["train_rmse"] = rmse
    
    return models

def predict_with_model(model_name, models, X):
    """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    model_info = models[model_name]
    model = model_info["model"]
    
    if model_info["type"] == "polynomial":
        X_processed = model_info["poly_transform"].transform(X)
        return model.predict(X_processed)
    else:
        return model.predict(X)

def show_model_evaluation(models, data):
    """æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°ç»“æœ"""
    st.subheader("ğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ")
    
    # å‡†å¤‡è¯„ä¼°ç»“æœæ•°æ®
    eval_data = []
    for name, info in models.items():
        eval_data.append({
            "æ¨¡å‹": name,
            "è®­ç»ƒRÂ²": f"{info['train_r2']:.4f}",
            "äº¤å‰éªŒè¯RÂ²": f"{info['cv_r2_mean']:.4f} Â± {info['cv_r2_std']:.4f}",
            "è®­ç»ƒRMSE": f"{info['train_rmse']:.4f}"
        })
    
    eval_df = pd.DataFrame(eval_data)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹ï¼ˆäº¤å‰éªŒè¯RÂ²æœ€é«˜ï¼‰
    best_model = max(models.items(), key=lambda x: x[1]["cv_r2_mean"])[0]
    
    # æ˜¾ç¤ºè¯„ä¼°è¡¨æ ¼ï¼Œçªå‡ºæœ€ä½³æ¨¡å‹
    def highlight_best(row):
        return ['background-color: #90EE90' if row['æ¨¡å‹'] == best_model else '' for _ in row]
    
    styled_df = eval_df.style.apply(highlight_best, axis=1)
    st.dataframe(styled_df, use_container_width=True)
    
    st.info(f"æ¨èæ¨¡å‹: **{best_model}** (åŸºäºäº¤å‰éªŒè¯RÂ²æœ€é«˜)")

def show_visualizations(models, data, model_name):
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–ç»“æœ"""
    st.subheader("ğŸ” æ•°æ®å¯è§†åŒ–")
    
    # åˆ›å»ºç½‘æ ¼æ•°æ®ç”¨äºç»˜åˆ¶æ›²é¢
    x = data['Temp']
    y = data['Time']
    z = data['Force']
    
    x_range = np.linspace(x.min(), x.max(), 30)
    y_range = np.linspace(y.min(), y.max(), 30)
    X_grid, Y_grid = np.meshgrid(x_range, y_range)
    grid_data = np.column_stack([X_grid.ravel(), Y_grid.ravel()])
    
    # è·å–æ¨¡å‹é¢„æµ‹å€¼
    Z_grid = predict_with_model(model_name, models, grid_data)
    Z_grid = Z_grid.reshape(X_grid.shape)
    
    # åˆ†ä¸ºä¸¤åˆ—æ˜¾ç¤ºå›¾è¡¨
    col1, col2 = st.columns(2)
    
    with col1:
        # 3Dæ•£ç‚¹å›¾å’Œæ›²é¢å›¾ (ä½¿ç”¨plotly)
        st.subheader(f"3Då…³ç³»å›¾ ({model_name})")
        
        # åˆ›å»º3Då›¾å½¢
        fig = go.Figure()
        
        # æ·»åŠ åŸå§‹æ•°æ®ç‚¹
        fig.add_trace(go.Scatter3d(
            x=x, y=y, z=z,
            mode='markers',
            marker=dict(size=5, color='red'),
            name='å®éªŒæ•°æ®'
        ))
        
        # æ·»åŠ é¢„æµ‹æ›²é¢
        fig.add_trace(go.Surface(
            x=X_grid, y=Y_grid, z=Z_grid,
            opacity=0.6,
            colorscale='Viridis',
            name='é¢„æµ‹æ›²é¢'
        ))
        
        fig.update_layout(
            scene=dict(
                xaxis_title='æ¸©åº¦ (Â°C)',
                yaxis_title='æ—¶é—´ (s)',
                zaxis_title='æ¨å‡ºåŠ›'
            ),
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # çƒ­åŒºå›¾
        st.subheader(f"çƒ­åŒºå›¾ ({model_name})")
        
        # åˆ›å»ºçƒ­åŒºå›¾æ•°æ®
        z_dense = Z_grid
        fig = px.imshow(
            z_dense,
            x=x_range,
            y=y_range,
            color_continuous_scale='Viridis',
            aspect='auto',
            labels=dict(x="æ¸©åº¦ (Â°C)", y="æ—¶é—´ (s)", color="æ¨å‡ºåŠ›")
        )
        
        # æ·»åŠ åŸå§‹æ•°æ®ç‚¹
        fig.add_scatter(x=x, y=y, mode='markers', 
                       marker=dict(color='red', size=8, line=dict(width=2, color='black')),
                       name='å®éªŒæ•°æ®')
        
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    # ç›¸å…³æ€§åˆ†æ
    st.subheader("ğŸ“Š ç›¸å…³æ€§åˆ†æ")
    corr = data.corr()
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)
    st.pyplot(fig)

def show_prediction_tool(models, data, model_name):
    """æ˜¾ç¤ºäº¤äº’å¼é¢„æµ‹å·¥å…·"""
    st.subheader("ğŸ”® æ¨å‡ºåŠ›é¢„æµ‹")
    
    # è·å–æ•°æ®èŒƒå›´
    temp_min, temp_max = data['Temp'].min(), data['Temp'].max()
    time_min, time_max = data['Time'].min(), data['Time'].max()
    
    # æ·»åŠ ä¸€äº›ç¼“å†²
    temp_buffer = (temp_max - temp_min) * 0.1
    time_buffer = (time_max - time_min) * 0.1
    
    # åˆ›å»ºè¾“å…¥æ§ä»¶
    col1, col2 = st.columns(2)
    
    with col1:
        temp = st.slider(
            "æ¸©åº¦ (Â°C)",
            min_value=float(temp_min - temp_buffer),
            max_value=float(temp_max + temp_buffer),
            value=float(data['Temp'].mean())
        )
    
    with col2:
        time = st.slider(
            "æ—¶é—´ (s)",
            min_value=float(time_min - time_buffer),
            max_value=float(time_max + time_buffer),
            value=float(data['Time'].mean())
        )
    
    # é¢„æµ‹æ¨å‡ºåŠ›
    X_pred = pd.DataFrame([[temp, time]], columns=['Temp', 'Time'])
    force_pred = predict_with_model(model_name, models, X_pred)[0]
    
    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    st.metric("é¢„æµ‹æ¨å‡ºåŠ›", f"{force_pred:.4f}", delta=None)
    
    # æ˜¾ç¤ºæ¨¡å‹å½±å“åˆ†æ
    st.subheader("ğŸ“‹ å½±å“åˆ†æ")
    model_info = models[model_name]
    
    if model_name == "çº¿æ€§å›å½’":
        coefs = model_info["model"].coef_
        intercept = model_info["model"].intercept_
        
        st.latex(f"æ¨å‡ºåŠ› = {intercept:.4f} + {coefs[0]:.4f} \\times æ¸©åº¦ + {coefs[1]:.4f} \\times æ—¶é—´")
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        
        # åˆ†æå½±å“å¤§å°
        temp_impact = abs(coefs[0])
        time_impact = abs(coefs[1])
        
        if temp_impact > time_impact:
            st.info(f"æ¸©åº¦å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (å½±å“æ¯”ä¾‹: {temp_impact/time_impact:.2f}:1)")
        elif time_impact > temp_impact:
            st.info(f"æ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (å½±å“æ¯”ä¾‹: 1:{time_impact/temp_impact:.2f})")
        else:
            st.info("æ¸©åº¦å’Œæ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“å¤§è‡´ç›¸åŒ")
    
    elif model_name == "å¤šé¡¹å¼å›å½’":
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        st.info("æ¨¡å‹åŒ…å«æ¸©åº¦ã€æ—¶é—´çš„äºŒæ¬¡é¡¹ä»¥åŠäº¤äº’é¡¹ï¼Œè¡¨æ˜å®ƒä»¬å¯¹æ¨å‡ºåŠ›çš„å½±å“æ˜¯éçº¿æ€§çš„ï¼Œåœ¨ä¸åŒèŒƒå›´å†…å½±å“ç¨‹åº¦ä¸åŒ")
    
    else:  # éšæœºæ£®æ—å’Œæ¢¯åº¦æå‡æ ‘
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        
        # ç‰¹å¾é‡è¦æ€§
        importances = model_info["model"].feature_importances_
        temp_importance = importances[0]
        time_importance = importances[1]
        
        st.write(f"æ¸©åº¦ç‰¹å¾é‡è¦æ€§: {temp_importance:.4f}")
        st.write(f"æ—¶é—´ç‰¹å¾é‡è¦æ€§: {time_importance:.4f}")
        
        if temp_importance > time_importance:
            st.info(f"æ¸©åº¦å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (é‡è¦æ€§æ¯”ä¾‹: {temp_importance/time_importance:.2f}:1)")
        elif time_importance > temp_importance:
            st.info(f"æ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (é‡è¦æ€§æ¯”ä¾‹: 1:{time_importance/temp_importance:.2f})")
        else:
            st.info("æ¸©åº¦å’Œæ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“å¤§è‡´ç›¸åŒ")

# æ·»åŠ é¡µè„šä¿¡æ¯
def add_footer():
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center;">
        <p>å›¢é˜Ÿè´¡çŒ®æ•°æ®åˆ†æå·¥å…· | æ•°æ®æ¥æºäºä¸Šä¼ çš„CSVæ–‡ä»¶</p>
        <p>Â© 2023 å›¢é˜Ÿè´¡çŒ®åˆ†æé¡¹ç›®</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
    add_footer()
    
